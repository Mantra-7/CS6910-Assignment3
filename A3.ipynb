{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# import other libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('aksharantar_sampled/hin/hin_train.csv')\n",
    "test_data = pd.read_csv('aksharantar_sampled/hin/hin_test.csv')\n",
    "valid_data = pd.read_csv('aksharantar_sampled/hin/hin_valid.csv')\n",
    "\n",
    "# rename columns ['input_seq', 'target_seq']\n",
    "train_data.columns = ['input_seq', 'target_seq']\n",
    "test_data.columns = ['input_seq', 'target_seq']\n",
    "valid_data.columns = ['input_seq', 'target_seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_seq</th>\n",
       "      <th>target_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bindhya</td>\n",
       "      <td>बिन्द्या</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kirankant</td>\n",
       "      <td>किरणकांत</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yagyopaveet</td>\n",
       "      <td>यज्ञोपवीत</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ratania</td>\n",
       "      <td>रटानिया</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vaganyache</td>\n",
       "      <td>वागण्याचे</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     input_seq target_seq\n",
       "0      bindhya   बिन्द्या\n",
       "1    kirankant   किरणकांत\n",
       "2  yagyopaveet  यज्ञोपवीत\n",
       "3      ratania    रटानिया\n",
       "4   vaganyache  वागण्याचे"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Lang\n",
    "class Lang:\n",
    "\tdef __init__(self, wordList):\n",
    "\t\tself.char2index = {'A': 0, 'Z': 1}\n",
    "\t\tself.char2count = {}\n",
    "\t\tself.index2char = {0: 'A', 1: 'Z'}\n",
    "\t\tself.n_chars = 2\n",
    "\n",
    "\t\tfor word in wordList:\n",
    "\t\t\tself.addWord(word)\n",
    "\n",
    "\tdef addWord(self, word):\n",
    "\t\tfor char in word:\n",
    "\t\t\tself.addChar(char)\n",
    "\n",
    "\tdef addChar(self, char):\n",
    "\t\tif char not in self.char2index:\n",
    "\t\t\tself.char2index[char] = self.n_chars\n",
    "\t\t\tself.char2count[char] = 1\n",
    "\t\t\tself.index2char[self.n_chars] = char\n",
    "\t\t\tself.n_chars += 1\n",
    "\t\telse:\n",
    "\t\t\tself.char2count[char] += 1\n",
    "\n",
    "\tdef encode(self, word):\n",
    "\t\tembedded = []\n",
    "\t\tfor i in range(len(word)):\n",
    "\t\t\tembedded.append([self.char2index[word[i]]])\n",
    "\t\treturn Variable(torch.LongTensor(embedded))\n",
    "\n",
    "\tdef one_hot_encode(self, word):\n",
    "\t\tone_hot = torch.zeros(len(word), self.n_chars)\n",
    "\t\tfor i in range(len(word)):\n",
    "\t\t\tone_hot[i][self.char2index[word[i]]] = 1\n",
    "\t\treturn one_hot\n",
    "\t\n",
    "\tdef one_hot_encode_char(self, char):\n",
    "\t\tone_hot = torch.zeros(1, self.n_chars)\n",
    "\t\tone_hot[0][self.char2index[char]] = 1\n",
    "\t\treturn one_hot\n",
    "\t\n",
    "\tdef decode(self, word):\n",
    "\t\tdecoded = ''\n",
    "\t\tfor i in range(len(word)):\n",
    "\t\t\tdecoded += self.index2char[word[i]]\n",
    "\t\treturn decoded\n",
    "\t\n",
    "\tdef decode_one_hot(self, word):\n",
    "\t\tdecoded = ''\n",
    "\t\tfor i in range(len(word)):\n",
    "\t\t\tdecoded += self.index2char[word[i].argmax().item()]\n",
    "\t\treturn decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "class AksharantarDataset(Dataset):\n",
    "\tdef __init__(self, data, inp_lang, out_lang):\n",
    "\t\tself.data = data\n",
    "\t\tself.inp_lang = inp_lang\n",
    "\t\tself.out_lang = out_lang\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.data)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tif torch.is_tensor(idx):\n",
    "\t\t\tidx = idx.tolist()\n",
    "\n",
    "\t\tinp_seq = self.inp_lang.one_hot_encode(self.data['input_seq'][idx]).unsqueeze(1)\n",
    "\t\tout_seq = self.out_lang.one_hot_encode(self.data['target_seq'][idx]).unsqueeze(1)\n",
    "\n",
    "\t\tsample = {'input_seq': inp_seq, 'target_seq': out_seq}\n",
    "\t\treturn sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_lang = Lang(train_data['input_seq'])\n",
    "out_lang = Lang(train_data['target_seq'])\n",
    "\n",
    "train_dataset = AksharantarDataset(train_data, inp_lang, out_lang)\n",
    "test_dataset = AksharantarDataset(test_data, inp_lang, out_lang)\n",
    "valid_dataset = AksharantarDataset(valid_data, inp_lang, out_lang)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a seq2seq model using 2 RNNs\n",
    "class Seq2Seq(nn.Module):\n",
    "\tdef __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "\t\tsuper(Seq2Seq, self).__init__()\n",
    "\t\tself.input_size = input_size\n",
    "\t\tself.hidden_size = hidden_size\n",
    "\t\tself.output_size = output_size\n",
    "\t\tself.n_layers = n_layers\n",
    "\t\t\t\t\n",
    "\t\t# encoder and decoder\n",
    "\t\tself.encoder = nn.RNN(input_size, hidden_size, n_layers)\n",
    "\t\tself.decoder = nn.RNN(hidden_size, hidden_size, n_layers)\n",
    "\n",
    "\t\t# linear layer to get output\n",
    "\t\tself.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "\tdef forward(self, input, hidden):\n",
    "\t\t# encoder\n",
    "\t\toutput, hidden = self.encoder(input, hidden)\n",
    "\t\t\n",
    "\t\t# decoder\n",
    "\t\toutput, hidden = self.decoder(output, hidden)\n",
    "\t\t\n",
    "\t\t# get output\n",
    "\t\toutput = self.linear(output)\n",
    "\t\treturn output, hidden\n",
    "\t\n",
    "\tdef predict(self, input, out_lang):\n",
    "\t\tout, hidden = self.forward(input, self.init_hidden(1))\n",
    "\t\treturn out_lang.decode_one_hot(out)\n",
    "\t\n",
    "\tdef init_hidden(self, batch_size):\n",
    "\t\treturn Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(inp_lang.n_chars, 128, out_lang.n_chars, 1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# train 1 input\n",
    "def train(input_variable, target_variable):\n",
    "\t# zero gradients\n",
    "\toptimizer.zero_grad()\n",
    "\t\n",
    "\t# initialize hidden layer\n",
    "\thidden = model.init_hidden(1)\n",
    "\t\n",
    "\t# get output\n",
    "\toutput, hidden = model.forward(input_variable, hidden)\n",
    "\t\n",
    "\tmx_len = min(len(output), len(target_variable))\n",
    "\n",
    "\t# pad output and target_variable with 'Z'\n",
    "\twhile(len(output) < len(target_variable)):\n",
    "\t\toutput = torch.cat((output, out_lang.one_hot_encode_char('Z').view(1, 1, -1)), 0)\n",
    "\n",
    "\twhile(len(target_variable) < len(output)):\n",
    "\t\ttarget_variable = torch.cat((target_variable, out_lang.one_hot_encode_char('Z').view(1, 1, -1)), 0)\n",
    "\t\n",
    "\t# calculate loss \n",
    "\tloss = criterion(torch.flatten(output[:mx_len], 0, 1), torch.flatten(target_variable[:mx_len], 0, 1).max(1)[1])\n",
    "\t\t\n",
    "\t# backpropagate\n",
    "\tloss.backward()\n",
    "\t\n",
    "\t# update weights\n",
    "\toptimizer.step()\n",
    "\n",
    "\treturn loss.data.item() / len(input_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# train 1 epoch\n",
    "def trainEpoch(epoch):\n",
    "\tlosses = []\n",
    "\tfor i in tqdm(range(len(train_data))):\n",
    "\t\tloss = train(inp_lang.one_hot_encode(train_data['input_seq'][i]).unsqueeze(1), out_lang.one_hot_encode(train_data['target_seq'][i]).unsqueeze(1))\n",
    "\t\tlosses.append(loss)\n",
    "\t\tprint('Epoch: %d, Loss: %.4f' % (epoch, np.mean(losses)))\n",
    "\n",
    "def trainEpochDataLoader(epoch):\n",
    "\tlosses = []\n",
    "\tfor i_batch, sample_batched in enumerate(train_dataloader):\n",
    "\t\tloss = train(sample_batched['input_seq'], sample_batched['target_seq'])\n",
    "\t\tlosses.append(loss)\n",
    "\t\tprint('Epoch: %d, Loss: %.4f' % (epoch, np.mean(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/51199 [00:00<04:21, 195.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.6048\n",
      "Epoch: 0, Loss: 0.5328\n",
      "Epoch: 0, Loss: 0.4815\n",
      "Epoch: 0, Loss: 0.5075\n",
      "Epoch: 0, Loss: 0.4880\n",
      "Epoch: 0, Loss: 0.4528\n",
      "Epoch: 0, Loss: 0.4538\n",
      "Epoch: 0, Loss: 0.4704\n",
      "Epoch: 0, Loss: 0.4556\n",
      "Epoch: 0, Loss: 0.4780\n",
      "Epoch: 0, Loss: 0.4642\n",
      "Epoch: 0, Loss: 0.4579\n",
      "Epoch: 0, Loss: 0.4481\n",
      "Epoch: 0, Loss: 0.4503\n",
      "Epoch: 0, Loss: 0.4844\n",
      "Epoch: 0, Loss: 0.4716\n",
      "Epoch: 0, Loss: 0.4694\n",
      "Epoch: 0, Loss: 0.4821\n",
      "Epoch: 0, Loss: 0.4841\n",
      "Epoch: 0, Loss: 0.4857\n",
      "Epoch: 0, Loss: 0.4929\n",
      "Epoch: 0, Loss: 0.4868\n",
      "Epoch: 0, Loss: 0.4867\n",
      "Epoch: 0, Loss: 0.4833\n",
      "Epoch: 0, Loss: 0.4903\n",
      "Epoch: 0, Loss: 0.4884\n",
      "Epoch: 0, Loss: 0.4875\n",
      "Epoch: 0, Loss: 0.5122\n",
      "Epoch: 0, Loss: 0.5152\n",
      "Epoch: 0, Loss: 0.5148\n",
      "Epoch: 0, Loss: 0.5099\n",
      "Epoch: 0, Loss: 0.5073\n",
      "Epoch: 0, Loss: 0.5070\n",
      "Epoch: 0, Loss: 0.5103\n",
      "Epoch: 0, Loss: 0.5073\n",
      "Epoch: 0, Loss: 0.5040\n",
      "Epoch: 0, Loss: 0.5021\n",
      "Epoch: 0, Loss: 0.5031\n",
      "Epoch: 0, Loss: 0.4992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 68/51199 [00:00<03:50, 222.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.4991\n",
      "Epoch: 0, Loss: 0.4969\n",
      "Epoch: 0, Loss: 0.4925\n",
      "Epoch: 0, Loss: 0.5127\n",
      "Epoch: 0, Loss: 0.5117\n",
      "Epoch: 0, Loss: 0.5128\n",
      "Epoch: 0, Loss: 0.5090\n",
      "Epoch: 0, Loss: 0.5104\n",
      "Epoch: 0, Loss: 0.5089\n",
      "Epoch: 0, Loss: 0.5082\n",
      "Epoch: 0, Loss: 0.5037\n",
      "Epoch: 0, Loss: 0.5036\n",
      "Epoch: 0, Loss: 0.5047\n",
      "Epoch: 0, Loss: 0.5033\n",
      "Epoch: 0, Loss: 0.5012\n",
      "Epoch: 0, Loss: 0.4968\n",
      "Epoch: 0, Loss: 0.5049\n",
      "Epoch: 0, Loss: 0.5018\n",
      "Epoch: 0, Loss: 0.4984\n",
      "Epoch: 0, Loss: 0.5001\n",
      "Epoch: 0, Loss: 0.4973\n",
      "Epoch: 0, Loss: 0.4957\n",
      "Epoch: 0, Loss: 0.4937\n",
      "Epoch: 0, Loss: 0.4929\n",
      "Epoch: 0, Loss: 0.4888\n",
      "Epoch: 0, Loss: 0.4898\n",
      "Epoch: 0, Loss: 0.4903\n",
      "Epoch: 0, Loss: 0.4874\n",
      "Epoch: 0, Loss: 0.4847\n",
      "Epoch: 0, Loss: 0.4998\n",
      "Epoch: 0, Loss: 0.4983\n",
      "Epoch: 0, Loss: 0.4972\n",
      "Epoch: 0, Loss: 0.4949\n",
      "Epoch: 0, Loss: 0.4936\n",
      "Epoch: 0, Loss: 0.4916\n",
      "Epoch: 0, Loss: 0.4898\n",
      "Epoch: 0, Loss: 0.4897\n",
      "Epoch: 0, Loss: 0.4906\n",
      "Epoch: 0, Loss: 0.4889\n",
      "Epoch: 0, Loss: 0.4876\n",
      "Epoch: 0, Loss: 0.4863\n",
      "Epoch: 0, Loss: 0.4859\n",
      "Epoch: 0, Loss: 0.4877\n",
      "Epoch: 0, Loss: 0.4862"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 117/51199 [00:00<03:41, 230.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, Loss: 0.4866\n",
      "Epoch: 0, Loss: 0.4949\n",
      "Epoch: 0, Loss: 0.4978\n",
      "Epoch: 0, Loss: 0.4953\n",
      "Epoch: 0, Loss: 0.4994\n",
      "Epoch: 0, Loss: 0.4985\n",
      "Epoch: 0, Loss: 0.4986\n",
      "Epoch: 0, Loss: 0.4992\n",
      "Epoch: 0, Loss: 0.5024\n",
      "Epoch: 0, Loss: 0.5020\n",
      "Epoch: 0, Loss: 0.5004\n",
      "Epoch: 0, Loss: 0.4993\n",
      "Epoch: 0, Loss: 0.5011\n",
      "Epoch: 0, Loss: 0.5003\n",
      "Epoch: 0, Loss: 0.5014\n",
      "Epoch: 0, Loss: 0.4999\n",
      "Epoch: 0, Loss: 0.4985\n",
      "Epoch: 0, Loss: 0.4988\n",
      "Epoch: 0, Loss: 0.5007\n",
      "Epoch: 0, Loss: 0.4989\n",
      "Epoch: 0, Loss: 0.4988\n",
      "Epoch: 0, Loss: 0.4994\n",
      "Epoch: 0, Loss: 0.4982\n",
      "Epoch: 0, Loss: 0.4970\n",
      "Epoch: 0, Loss: 0.4987\n",
      "Epoch: 0, Loss: 0.5019\n",
      "Epoch: 0, Loss: 0.5012\n",
      "Epoch: 0, Loss: 0.4992\n",
      "Epoch: 0, Loss: 0.4993\n",
      "Epoch: 0, Loss: 0.4993\n",
      "Epoch: 0, Loss: 0.4971\n",
      "Epoch: 0, Loss: 0.4951\n",
      "Epoch: 0, Loss: 0.4939\n",
      "Epoch: 0, Loss: 0.4928\n",
      "Epoch: 0, Loss: 0.4911\n",
      "Epoch: 0, Loss: 0.4906\n",
      "Epoch: 0, Loss: 0.4897\n",
      "Epoch: 0, Loss: 0.4913\n",
      "Epoch: 0, Loss: 0.4904\n",
      "Epoch: 0, Loss: 0.4895\n",
      "Epoch: 0, Loss: 0.4878\n",
      "Epoch: 0, Loss: 0.4889\n",
      "Epoch: 0, Loss: 0.4878\n",
      "Epoch: 0, Loss: 0.4872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 165/51199 [00:00<03:44, 227.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.4871\n",
      "Epoch: 0, Loss: 0.4874\n",
      "Epoch: 0, Loss: 0.4859\n",
      "Epoch: 0, Loss: 0.4859\n",
      "Epoch: 0, Loss: 0.4870\n",
      "Epoch: 0, Loss: 0.4861\n",
      "Epoch: 0, Loss: 0.4854\n",
      "Epoch: 0, Loss: 0.4842\n",
      "Epoch: 0, Loss: 0.4826\n",
      "Epoch: 0, Loss: 0.4836\n",
      "Epoch: 0, Loss: 0.4879\n",
      "Epoch: 0, Loss: 0.4886\n",
      "Epoch: 0, Loss: 0.4879\n",
      "Epoch: 0, Loss: 0.4867\n",
      "Epoch: 0, Loss: 0.4866\n",
      "Epoch: 0, Loss: 0.4864\n",
      "Epoch: 0, Loss: 0.4849\n",
      "Epoch: 0, Loss: 0.4848\n",
      "Epoch: 0, Loss: 0.4833\n",
      "Epoch: 0, Loss: 0.4823\n",
      "Epoch: 0, Loss: 0.4815\n",
      "Epoch: 0, Loss: 0.4805\n",
      "Epoch: 0, Loss: 0.4807\n",
      "Epoch: 0, Loss: 0.4798\n",
      "Epoch: 0, Loss: 0.4785\n",
      "Epoch: 0, Loss: 0.4787\n",
      "Epoch: 0, Loss: 0.4779\n",
      "Epoch: 0, Loss: 0.4777\n",
      "Epoch: 0, Loss: 0.4762\n",
      "Epoch: 0, Loss: 0.4765\n",
      "Epoch: 0, Loss: 0.4764\n",
      "Epoch: 0, Loss: 0.4828\n",
      "Epoch: 0, Loss: 0.4817\n",
      "Epoch: 0, Loss: 0.4807\n",
      "Epoch: 0, Loss: 0.4837\n",
      "Epoch: 0, Loss: 0.4839\n",
      "Epoch: 0, Loss: 0.4838\n",
      "Epoch: 0, Loss: 0.4840\n",
      "Epoch: 0, Loss: 0.4825\n",
      "Epoch: 0, Loss: 0.4823\n",
      "Epoch: 0, Loss: 0.4819\n",
      "Epoch: 0, Loss: 0.4809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 189/51199 [00:00<03:42, 229.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.4796\n",
      "Epoch: 0, Loss: 0.4792\n",
      "Epoch: 0, Loss: 0.4792\n",
      "Epoch: 0, Loss: 0.4776\n",
      "Epoch: 0, Loss: 0.4814\n",
      "Epoch: 0, Loss: 0.4818\n",
      "Epoch: 0, Loss: 0.4812\n",
      "Epoch: 0, Loss: 0.4803\n",
      "Epoch: 0, Loss: 0.4797\n",
      "Epoch: 0, Loss: 0.4796\n",
      "Epoch: 0, Loss: 0.4804\n",
      "Epoch: 0, Loss: 0.4797\n",
      "Epoch: 0, Loss: 0.4797\n",
      "Epoch: 0, Loss: 0.4785\n",
      "Epoch: 0, Loss: 0.4780\n",
      "Epoch: 0, Loss: 0.4778\n",
      "Epoch: 0, Loss: 0.4778\n",
      "Epoch: 0, Loss: 0.4809\n",
      "Epoch: 0, Loss: 0.4804\n",
      "Epoch: 0, Loss: 0.4794\n",
      "Epoch: 0, Loss: 0.4795\n",
      "Epoch: 0, Loss: 0.4792\n",
      "Epoch: 0, Loss: 0.4786\n",
      "Epoch: 0, Loss: 0.4796\n",
      "Epoch: 0, Loss: 0.4814\n",
      "Epoch: 0, Loss: 0.4824\n",
      "Epoch: 0, Loss: 0.4834\n",
      "Epoch: 0, Loss: 0.4824\n",
      "Epoch: 0, Loss: 0.4817\n",
      "Epoch: 0, Loss: 0.4811\n",
      "Epoch: 0, Loss: 0.4810\n",
      "Epoch: 0, Loss: 0.4805\n",
      "Epoch: 0, Loss: 0.4803\n",
      "Epoch: 0, Loss: 0.4805\n",
      "Epoch: 0, Loss: 0.4810\n",
      "Epoch: 0, Loss: 0.4815\n",
      "Epoch: 0, Loss: 0.4812\n",
      "Epoch: 0, Loss: 0.4809\n",
      "Epoch: 0, Loss: 0.4801\n",
      "Epoch: 0, Loss: 0.4799\n",
      "Epoch: 0, Loss: 0.4789"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 235/51199 [00:01<03:56, 215.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, Loss: 0.4787\n",
      "Epoch: 0, Loss: 0.4782\n",
      "Epoch: 0, Loss: 0.4778\n",
      "Epoch: 0, Loss: 0.4776\n",
      "Epoch: 0, Loss: 0.4765\n",
      "Epoch: 0, Loss: 0.4758\n",
      "Epoch: 0, Loss: 0.4749\n",
      "Epoch: 0, Loss: 0.4744\n",
      "Epoch: 0, Loss: 0.4733\n",
      "Epoch: 0, Loss: 0.4728\n",
      "Epoch: 0, Loss: 0.4722\n",
      "Epoch: 0, Loss: 0.4715\n",
      "Epoch: 0, Loss: 0.4720\n",
      "Epoch: 0, Loss: 0.4718\n",
      "Epoch: 0, Loss: 0.4708\n",
      "Epoch: 0, Loss: 0.4712\n",
      "Epoch: 0, Loss: 0.4706\n",
      "Epoch: 0, Loss: 0.4705\n",
      "Epoch: 0, Loss: 0.4702\n",
      "Epoch: 0, Loss: 0.4699\n",
      "Epoch: 0, Loss: 0.4735\n",
      "Epoch: 0, Loss: 0.4731\n",
      "Epoch: 0, Loss: 0.4729\n",
      "Epoch: 0, Loss: 0.4719\n",
      "Epoch: 0, Loss: 0.4711\n",
      "Epoch: 0, Loss: 0.4714\n",
      "Epoch: 0, Loss: 0.4715\n",
      "Epoch: 0, Loss: 0.4712\n",
      "Epoch: 0, Loss: 0.4707\n",
      "Epoch: 0, Loss: 0.4699\n",
      "Epoch: 0, Loss: 0.4698\n",
      "Epoch: 0, Loss: 0.4695\n",
      "Epoch: 0, Loss: 0.4720\n",
      "Epoch: 0, Loss: 0.4718\n",
      "Epoch: 0, Loss: 0.4715\n",
      "Epoch: 0, Loss: 0.4707\n",
      "Epoch: 0, Loss: 0.4705\n",
      "Epoch: 0, Loss: 0.4704\n",
      "Epoch: 0, Loss: 0.4702\n",
      "Epoch: 0, Loss: 0.4703"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 279/51199 [00:01<04:03, 209.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, Loss: 0.4709\n",
      "Epoch: 0, Loss: 0.4700\n",
      "Epoch: 0, Loss: 0.4692\n",
      "Epoch: 0, Loss: 0.4688\n",
      "Epoch: 0, Loss: 0.4688\n",
      "Epoch: 0, Loss: 0.4685\n",
      "Epoch: 0, Loss: 0.4679\n",
      "Epoch: 0, Loss: 0.4679\n",
      "Epoch: 0, Loss: 0.4676\n",
      "Epoch: 0, Loss: 0.4680\n",
      "Epoch: 0, Loss: 0.4687\n",
      "Epoch: 0, Loss: 0.4683\n",
      "Epoch: 0, Loss: 0.4679\n",
      "Epoch: 0, Loss: 0.4677\n",
      "Epoch: 0, Loss: 0.4673\n",
      "Epoch: 0, Loss: 0.4670\n",
      "Epoch: 0, Loss: 0.4670\n",
      "Epoch: 0, Loss: 0.4670\n",
      "Epoch: 0, Loss: 0.4664\n",
      "Epoch: 0, Loss: 0.4662\n",
      "Epoch: 0, Loss: 0.4659\n",
      "Epoch: 0, Loss: 0.4652\n",
      "Epoch: 0, Loss: 0.4648\n",
      "Epoch: 0, Loss: 0.4643\n",
      "Epoch: 0, Loss: 0.4648\n",
      "Epoch: 0, Loss: 0.4643\n",
      "Epoch: 0, Loss: 0.4650\n",
      "Epoch: 0, Loss: 0.4646\n",
      "Epoch: 0, Loss: 0.4650\n",
      "Epoch: 0, Loss: 0.4647\n",
      "Epoch: 0, Loss: 0.4647\n",
      "Epoch: 0, Loss: 0.4649\n",
      "Epoch: 0, Loss: 0.4644\n",
      "Epoch: 0, Loss: 0.4638\n",
      "Epoch: 0, Loss: 0.4637\n",
      "Epoch: 0, Loss: 0.4630"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 301/51199 [00:01<04:09, 203.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, Loss: 0.4628\n",
      "Epoch: 0, Loss: 0.4624\n",
      "Epoch: 0, Loss: 0.4616\n",
      "Epoch: 0, Loss: 0.4614\n",
      "Epoch: 0, Loss: 0.4620\n",
      "Epoch: 0, Loss: 0.4611\n",
      "Epoch: 0, Loss: 0.4602\n",
      "Epoch: 0, Loss: 0.4599\n",
      "Epoch: 0, Loss: 0.4595\n",
      "Epoch: 0, Loss: 0.4591\n",
      "Epoch: 0, Loss: 0.4594\n",
      "Epoch: 0, Loss: 0.4594\n",
      "Epoch: 0, Loss: 0.4590\n",
      "Epoch: 0, Loss: 0.4584\n",
      "Epoch: 0, Loss: 0.4584\n",
      "Epoch: 0, Loss: 0.4578\n",
      "Epoch: 0, Loss: 0.4576\n",
      "Epoch: 0, Loss: 0.4573\n",
      "Epoch: 0, Loss: 0.4566\n",
      "Epoch: 0, Loss: 0.4561\n",
      "Epoch: 0, Loss: 0.4560\n",
      "Epoch: 0, Loss: 0.4556\n",
      "Epoch: 0, Loss: 0.4561\n",
      "Epoch: 0, Loss: 0.4559\n",
      "Epoch: 0, Loss: 0.4566\n",
      "Epoch: 0, Loss: 0.4565\n",
      "Epoch: 0, Loss: 0.4562\n",
      "Epoch: 0, Loss: 0.4557\n",
      "Epoch: 0, Loss: 0.4554\n",
      "Epoch: 0, Loss: 0.4547\n",
      "Epoch: 0, Loss: 0.4552\n",
      "Epoch: 0, Loss: 0.4548\n",
      "Epoch: 0, Loss: 0.4545\n",
      "Epoch: 0, Loss: 0.4544\n",
      "Epoch: 0, Loss: 0.4540\n",
      "Epoch: 0, Loss: 0.4533"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 343/51199 [00:01<04:11, 202.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, Loss: 0.4531\n",
      "Epoch: 0, Loss: 0.4538\n",
      "Epoch: 0, Loss: 0.4539\n",
      "Epoch: 0, Loss: 0.4536\n",
      "Epoch: 0, Loss: 0.4529\n",
      "Epoch: 0, Loss: 0.4522\n",
      "Epoch: 0, Loss: 0.4526\n",
      "Epoch: 0, Loss: 0.4531\n",
      "Epoch: 0, Loss: 0.4526\n",
      "Epoch: 0, Loss: 0.4523\n",
      "Epoch: 0, Loss: 0.4529\n",
      "Epoch: 0, Loss: 0.4530\n",
      "Epoch: 0, Loss: 0.4526\n",
      "Epoch: 0, Loss: 0.4536\n",
      "Epoch: 0, Loss: 0.4536\n",
      "Epoch: 0, Loss: 0.4545\n",
      "Epoch: 0, Loss: 0.4552\n",
      "Epoch: 0, Loss: 0.4553\n",
      "Epoch: 0, Loss: 0.4554\n",
      "Epoch: 0, Loss: 0.4555\n",
      "Epoch: 0, Loss: 0.4556\n",
      "Epoch: 0, Loss: 0.4556\n",
      "Epoch: 0, Loss: 0.4554\n",
      "Epoch: 0, Loss: 0.4556\n",
      "Epoch: 0, Loss: 0.4553\n",
      "Epoch: 0, Loss: 0.4549\n",
      "Epoch: 0, Loss: 0.4551\n",
      "Epoch: 0, Loss: 0.4545\n",
      "Epoch: 0, Loss: 0.4547\n",
      "Epoch: 0, Loss: 0.4547\n",
      "Epoch: 0, Loss: 0.4548\n",
      "Epoch: 0, Loss: 0.4544\n",
      "Epoch: 0, Loss: 0.4542\n",
      "Epoch: 0, Loss: 0.4541\n",
      "Epoch: 0, Loss: 0.4538\n",
      "Epoch: 0, Loss: 0.4534\n",
      "Epoch: 0, Loss: 0.4535\n",
      "Epoch: 0, Loss: 0.4532\n",
      "Epoch: 0, Loss: 0.4529\n",
      "Epoch: 0, Loss: 0.4532\n",
      "Epoch: 0, Loss: 0.4529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 387/51199 [00:01<04:04, 207.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.4526\n",
      "Epoch: 0, Loss: 0.4525\n",
      "Epoch: 0, Loss: 0.4534\n",
      "Epoch: 0, Loss: 0.4541\n",
      "Epoch: 0, Loss: 0.4539\n",
      "Epoch: 0, Loss: 0.4543\n",
      "Epoch: 0, Loss: 0.4538\n",
      "Epoch: 0, Loss: 0.4544\n",
      "Epoch: 0, Loss: 0.4549\n",
      "Epoch: 0, Loss: 0.4547\n",
      "Epoch: 0, Loss: 0.4544\n",
      "Epoch: 0, Loss: 0.4544\n",
      "Epoch: 0, Loss: 0.4538\n",
      "Epoch: 0, Loss: 0.4536\n",
      "Epoch: 0, Loss: 0.4543\n",
      "Epoch: 0, Loss: 0.4541\n",
      "Epoch: 0, Loss: 0.4539\n",
      "Epoch: 0, Loss: 0.4535\n",
      "Epoch: 0, Loss: 0.4532\n",
      "Epoch: 0, Loss: 0.4529\n",
      "Epoch: 0, Loss: 0.4526\n",
      "Epoch: 0, Loss: 0.4535\n",
      "Epoch: 0, Loss: 0.4537\n",
      "Epoch: 0, Loss: 0.4530\n",
      "Epoch: 0, Loss: 0.4527\n",
      "Epoch: 0, Loss: 0.4528\n",
      "Epoch: 0, Loss: 0.4529\n",
      "Epoch: 0, Loss: 0.4527\n",
      "Epoch: 0, Loss: 0.4526\n",
      "Epoch: 0, Loss: 0.4522\n",
      "Epoch: 0, Loss: 0.4521\n",
      "Epoch: 0, Loss: 0.4517\n",
      "Epoch: 0, Loss: 0.4515\n",
      "Epoch: 0, Loss: 0.4511\n",
      "Epoch: 0, Loss: 0.4507\n",
      "Epoch: 0, Loss: 0.4522\n",
      "Epoch: 0, Loss: 0.4527\n",
      "Epoch: 0, Loss: 0.4527\n",
      "Epoch: 0, Loss: 0.4534\n",
      "Epoch: 0, Loss: 0.4536\n",
      "Epoch: 0, Loss: 0.4533\n",
      "Epoch: 0, Loss: 0.4537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 435/51199 [00:02<03:55, 215.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.4533\n",
      "Epoch: 0, Loss: 0.4533\n",
      "Epoch: 0, Loss: 0.4538\n",
      "Epoch: 0, Loss: 0.4537\n",
      "Epoch: 0, Loss: 0.4535\n",
      "Epoch: 0, Loss: 0.4533\n",
      "Epoch: 0, Loss: 0.4527\n",
      "Epoch: 0, Loss: 0.4524\n",
      "Epoch: 0, Loss: 0.4519\n",
      "Epoch: 0, Loss: 0.4518\n",
      "Epoch: 0, Loss: 0.4514\n",
      "Epoch: 0, Loss: 0.4511\n",
      "Epoch: 0, Loss: 0.4515\n",
      "Epoch: 0, Loss: 0.4516\n",
      "Epoch: 0, Loss: 0.4512\n",
      "Epoch: 0, Loss: 0.4511\n",
      "Epoch: 0, Loss: 0.4509\n",
      "Epoch: 0, Loss: 0.4511\n",
      "Epoch: 0, Loss: 0.4511\n",
      "Epoch: 0, Loss: 0.4509\n",
      "Epoch: 0, Loss: 0.4510\n",
      "Epoch: 0, Loss: 0.4507\n",
      "Epoch: 0, Loss: 0.4503\n",
      "Epoch: 0, Loss: 0.4506\n",
      "Epoch: 0, Loss: 0.4510\n",
      "Epoch: 0, Loss: 0.4508\n",
      "Epoch: 0, Loss: 0.4507\n",
      "Epoch: 0, Loss: 0.4506\n",
      "Epoch: 0, Loss: 0.4508\n",
      "Epoch: 0, Loss: 0.4506\n",
      "Epoch: 0, Loss: 0.4507\n",
      "Epoch: 0, Loss: 0.4501\n",
      "Epoch: 0, Loss: 0.4499\n",
      "Epoch: 0, Loss: 0.4497\n",
      "Epoch: 0, Loss: 0.4493\n",
      "Epoch: 0, Loss: 0.4501\n",
      "Epoch: 0, Loss: 0.4499\n",
      "Epoch: 0, Loss: 0.4497\n",
      "Epoch: 0, Loss: 0.4493\n",
      "Epoch: 0, Loss: 0.4487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 463/51199 [00:02<04:02, 209.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.4484\n",
      "Epoch: 0, Loss: 0.4481\n",
      "Epoch: 0, Loss: 0.4480\n",
      "Epoch: 0, Loss: 0.4482\n",
      "Epoch: 0, Loss: 0.4482\n",
      "Epoch: 0, Loss: 0.4482\n",
      "Epoch: 0, Loss: 0.4491\n",
      "Epoch: 0, Loss: 0.4491\n",
      "Epoch: 0, Loss: 0.4491\n",
      "Epoch: 0, Loss: 0.4490\n",
      "Epoch: 0, Loss: 0.4488\n",
      "Epoch: 0, Loss: 0.4484\n",
      "Epoch: 0, Loss: 0.4489\n",
      "Epoch: 0, Loss: 0.4484\n",
      "Epoch: 0, Loss: 0.4480\n",
      "Epoch: 0, Loss: 0.4478\n",
      "Epoch: 0, Loss: 0.4476\n",
      "Epoch: 0, Loss: 0.4475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13796/818335479.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# train 10 epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mtrainEpoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13796/2918801962.py\u001b[0m in \u001b[0;36mtrainEpoch\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp_lang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_hot_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_seq'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_lang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_hot_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target_seq'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m                 \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch: %d, Loss: %.4f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13796/1779658177.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(input_variable, target_variable)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# get output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_variable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mmx_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_variable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13796/254304239.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hidden)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[1;31m# encoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                 \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[1;31m# decoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'RNN_TANH'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m                 result = _VF.rnn_tanh(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[0;32m    477\u001b[0m                                       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m                                       self.batch_first)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train 10 epochs\n",
    "for i in range(10):\n",
    "\ttrainEpoch(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'धुरुव'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out, hid = model.forward(eng.one_hot_encode('dhruv').unsqueeze(1), model.init_hidden(1))\n",
    "\n",
    "hin.decode_one_hot(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
